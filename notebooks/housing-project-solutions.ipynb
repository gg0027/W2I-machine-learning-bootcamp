{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import plotting\n",
    "from scipy import stats\n",
    "from sklearn import base\n",
    "from sklearn import compose, impute, pipeline, preprocessing\n",
    "from sklearn import linear_model, tree, ensemble, svm\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my solutions to Chapter 2 of _Hands-on Machine Learning with Scikit-learn and TensorFlow_. Author's solutions are also avalable on GitHub.\n",
    "\n",
    "* https://github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb\n",
    "\n",
    "Major difference between my solutions and the authors is that my solutions take advantage of some newer features of the Scikit-Learn [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) module and the new [compose](https://scikit-learn.org/stable/modules/compose.html#combining-estimators) module for composing analysis pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data\n",
    "\n",
    "In general you want to automate as much of the process of accessing the data as possible in order to make it easier to get fresh data as it becomes available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(datasets_url):\n",
    "    path, _ = urllib.request.urlretrieve(f\"{datasets_url}/housing/housing.tgz\",\n",
    "                                         \"../data/housing/housing.tgz\")\n",
    "    with tarfile.open(path) as tf:\n",
    "        tf.extractall(\"../data/housing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_datasets_url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets\"\n",
    "fetch_housing_data(_datasets_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dtype = {\"ocean_proximity\": \"category\"}\n",
    "\n",
    "housing_df = pd.read_csv(\"../data/housing/housing.csv\",\n",
    "                         dtype=_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a Quick Look at the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flat text files (such as CSV files) are inefficient storage formats.\n",
    "\n",
    "* Flat text files are schema-less: data-type information is not stored together with the data so it must be re-coded everytime the raw data is loaded.\n",
    "* Flat text files can not be efficiently stored.\n",
    "* Flat text files can not be efficiently queried.\n",
    "\n",
    "Always a good idea to convert raw text files to efficienty storage formats such as [Apache Parquet](https://parquet.apache.org/) first and then read/query the data from the resulting parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.to_parquet(\"../data/housing/housing.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "_table = (pq.ParquetFile(\"../data/housing/housing.parquet\")\n",
    "            .read(use_pandas_metadata=True))\n",
    "\n",
    "housing_df = _table.to_pandas(strings_to_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(housing_df.get(\"ocean_proximity\")\n",
    "           .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = housing_df.hist(bins=50, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.KBinsDiscretizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_prng = np.random.RandomState(42)\n",
    "\n",
    "# discretize a continuous variable and use result for stratified sampling!\n",
    "_discretizer = preprocessing.KBinsDiscretizer(n_bins=5, encode=\"ordinal\")\n",
    "_stratify = _discretizer.fit_transform(housing_df.loc[:, [\"median_income\"]])\n",
    "\n",
    "training_df, testing_df = model_selection.train_test_split(housing_df,\n",
    "                                                           test_size=0.20,\n",
    "                                                           stratify= _stratify,\n",
    "                                                           random_state=_prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(training_df, \"../data/housing/training.pkl\")\n",
    "_ = joblib.dump(testing_df, \"../data/housing/testing.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover and Visualize the Data to Gain Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = joblib.load(\"../data/housing/training.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Geographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig, _ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "_marker_sizes = (training_df.loc[:, \"population\"]\n",
    "                            .div(100))\n",
    "\n",
    "_cmap = plt.get_cmap(\"viridis\")\n",
    "\n",
    "_kwargs = {'c': \"median_house_value\",\n",
    "           's': _marker_sizes,\n",
    "           \"label\": \"population\",\n",
    "           \"alpha\": 0.4,\n",
    "           \"cmap\": _cmap,\n",
    "           \"ax\": _ax}\n",
    "\n",
    "_ = (training_df.plot\n",
    "                .scatter(x=\"longitude\", y=\"latitude\", **_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_df.corr()\n",
    "            .loc[:, \"median_house_value\"]\n",
    "            .sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_attributes = [\"median_house_value\",\n",
    "               \"median_income\",\n",
    "               \"total_rooms\",\n",
    "               \"housing_median_age\"]\n",
    "\n",
    "_ = plotting.scatter_matrix(training_df.loc[:, _attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = (training_df.plot\n",
    "                .scatter(x=\"median_income\", y=\"median_house_value\", alpha=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Attribute Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingFeatureCreator(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        \n",
    "        # examples of hand-crafted features\n",
    "        _rooms_per_household = (df.loc[:, \"total_rooms\"]\n",
    "                                  .div(df.loc[:, \"households\"]))\n",
    "        _bedrooms_per_room = (df.loc[:, \"total_bedrooms\"]\n",
    "                                .div(df.loc[:, \"total_rooms\"]))\n",
    "        _population_per_household = (df.loc[:, \"population\"]\n",
    "                                       .div(df.loc[:,\"households\"]))\n",
    "\n",
    "        _features = {\"rooms_per_household\": _rooms_per_household,\n",
    "                     \"bedrooms_per_room\": _bedrooms_per_room,\n",
    "                     \"population_per_household\": _population_per_household}\n",
    "\n",
    "        return df.assign(**_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_creator = HousingFeatureCreator()\n",
    "transformed_features_df = feature_creator.fit_transform(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(transformed_features_df.corr()\n",
    "                        .loc[:, \"median_house_value\"]\n",
    "                        .sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data for ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_df.isna()\n",
    "            .sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute.SimpleImputer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Text and Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.OneHotEncoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.OrdinalEncoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.StandardScaler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.make_pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features_transformer = pipeline.make_pipeline(\n",
    "    impute.SimpleImputer(strategy=\"median\"),\n",
    "    preprocessing.StandardScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_transformer = pipeline.make_pipeline(\n",
    "    impute.SimpleImputer(strategy=\"most_frequent\"),\n",
    "    preprocessing.OneHotEncoder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose.make_column_transformer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_numerical_columns = [\"longitude\",\n",
    "                      \"latitude\",\n",
    "                      \"housing_median_age\",\n",
    "                      \"total_rooms\",\n",
    "                      \"total_bedrooms\",\n",
    "                      \"population\",\n",
    "                      \"households\",\n",
    "                      \"median_income\",\n",
    "                      \"rooms_per_household\",\n",
    "                      \"bedrooms_per_room\",\n",
    "                      \"population_per_household\"]\n",
    "\n",
    "_categorical_columns = [\"ocean_proximity\"]\n",
    "\n",
    "column_transformer = compose.make_column_transformer(\n",
    "    (numeric_features_transformer, _numerical_columns),\n",
    "    (categorical_features_transformer, _categorical_columns),\n",
    "    remainder=\"drop\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = pipeline.make_pipeline(\n",
    "    feature_creator,\n",
    "    column_transformer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features_arr = preprocessing_pipeline.fit_transform(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 numeric features + 5 one-hot encoded categorical feature = 16 cols!\n",
    "training_features_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_target_arr = (training_df.loc[:, \"median_house_value\"]\n",
    "                                  .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_target_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating on the Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "See the Scikit-learn [docs](https://scikit-learn.org/stable/modules/linear_model.html) on Linear Regression for more details about this regression technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor = linear_model.LinearRegression(fit_intercept=False)\n",
    "linear_regressor.fit(training_features_arr, training_target_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor_predictions = linear_regressor.predict(training_features_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_target_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor_mse = metrics.mean_squared_error(training_target_arr, linear_regressor_predictions)\n",
    "linear_regressor_rmse = linear_regressor_mse**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error units are USD!\n",
    "linear_regressor_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(linear_regressor, \"../models/housing/linear-regressor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "\n",
    "See Scikit-learn [docs](https://scikit-learn.org/stable/modules/tree.html) on decision trees for the details of this regression technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_regressor = tree.DecisionTreeRegressor()\n",
    "decision_tree_regressor.fit(training_features_arr, training_target_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_regressor_predictions = decision_tree_regressor.predict(training_features_arr)\n",
    "decision_tree_regressor_mse = metrics.mean_squared_error(training_target_arr, decision_tree_regressor_predictions)\n",
    "decision_tree_regressor_rmse = decision_tree_regressor_mse**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_regressor_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(decision_tree_regressor, \"../models/housing/decision-tree-regressor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "\n",
    "See the Scikit-learn [docs](https://scikit-learn.org/stable/modules/ensemble.html) on Random Forests for more information about this regression technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_regressor = ensemble.RandomForestRegressor()\n",
    "random_forest_regressor.fit(training_features_arr, training_target_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(regressor):\n",
    "    _predictions = regressor.predict(training_features_arr)\n",
    "    _mse = metrics.mean_squared_error(training_target_arr, _predictions)\n",
    "    rmse = _mse**0.5\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_rmse(random_forest_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(random_forest_regressor, \"../models/housing/random-forest-regressor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees\n",
    "\n",
    "See the Scikit-learn [docs](https://scikit-learn.org/stable/modules/ensemble.html) on Gradient Boosted Trees for more information about this regression technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_regressor = ensemble.GradientBoostingRegressor()\n",
    "gradient_boosting_regressor.fit(training_features_arr, training_target_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_rmse(gradient_boosting_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(gradient_boosting_regressor, \"../models/housing/gradient-boosting-regressor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Evaluation using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_CV_FOLDS = 5\n",
    "NUMBER_CV_JOBS = 1 # NUMBER_CV_FOLDS\n",
    "VERBOSITY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [linear_regressor,\n",
    "              decision_tree_regressor,\n",
    "              random_forest_regressor,\n",
    "              gradient_boosting_regressor]\n",
    "\n",
    "cv_results = {}\n",
    "for regressor in regressors:\n",
    "    scores = model_selection.cross_val_score(regressor, \n",
    "                                             X=training_features_arr,\n",
    "                                             y=training_target_arr,\n",
    "                                             scoring=\"neg_mean_squared_error\",\n",
    "                                             cv=NUMBER_CV_FOLDS,\n",
    "                                             n_jobs= NUMBER_CV_JOBS,\n",
    "                                             verbose=VERBOSITY)\n",
    "    rmses = np.sqrt(-scores)\n",
    "    cv_results[regressor] = rmses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cv_results(cv_results):\n",
    "    for regressor, rmses in cv_results.items():\n",
    "        name = type(regressor).__name__\n",
    "        print(f\"Regressor: {name}\\n\\tAverage RMSE: {np.mean(rmses)}\\n\\tStandard Deviation RMSE: {np.std(rmses)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_param_grid = [\n",
    "    {\"n_estimators\": [3, 10, 30], \"max_features\": [2, 4, 6, 8]},\n",
    "    {\"bootstrap\": [False], \"n_estimators\": [3, 10], \"max_features\": [2, 3, 4]}\n",
    "]\n",
    "\n",
    "random_forest_grid_search = model_selection.GridSearchCV(random_forest_regressor,\n",
    "                                                         param_grid=_param_grid,\n",
    "                                                         scoring=\"neg_mean_squared_error\",\n",
    "                                                         cv=NUMBER_CV_FOLDS,\n",
    "                                                         n_jobs=NUMBER_CV_JOBS,\n",
    "                                                         verbose=VERBOSITY)\n",
    "\n",
    "random_forest_grid_search.fit(training_features_arr, training_target_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(random_forest_grid_search, \"../models/housing/random-forest-grid-search.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-random_forest_grid_search.best_score_)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.GradientBoostingRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_param_distributions = {\n",
    "    \"n_estimators\": stats.geom(p=0.01),\n",
    "     \"min_samples_split\": stats.beta(a=1, b=99),\n",
    "     \"min_samples_leaf\": stats.beta(a=1, b=999),\n",
    "}\n",
    "\n",
    "gradient_boosting_randomized_search = model_selection.RandomizedSearchCV(\n",
    "    gradient_boosting_regressor,\n",
    "    param_distributions=_param_distributions,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_iter=10,\n",
    "    cv=NUMBER_CV_FOLDS,\n",
    "    n_jobs=NUMBER_CV_JOBS,\n",
    "    verbose=VERBOSITY\n",
    ")\n",
    "\n",
    "gradient_boosting_randomized_search.fit(training_features_arr, training_target_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-gradient_boosting_randomized_search.best_score_)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = joblib.dump(gradient_boosting_randomized_search, \"../models/housing/gradient-boosting-randomized-search.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Best Models and Their Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(random_forest_grid_search.best_estimator_\n",
    "                          .feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ocean_proximity_categories = (training_df.loc[:, \"ocean_proximity\"]\n",
    "                                          .cat\n",
    "                                          .categories)\n",
    "_features_names = (_numerical_columns + list(_ocean_proximity_categories))\n",
    "\n",
    "_feature_importances = (random_forest_grid_search.best_estimator_\n",
    "                                                 .feature_importances_)\n",
    "sorted(zip(_feature_importances, _features_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_predictions = random_forest_grid_search.predict(training_features_arr)\n",
    "_residuals = training_target_arr - _predictions\n",
    "\n",
    "_fig, _ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "_marker_sizes = (training_df.loc[:, \"population\"]\n",
    "                            .div(100))\n",
    "\n",
    "_cmap = plt.get_cmap(\"viridis\")\n",
    "\n",
    "_kwargs = {'c': \"median_house_value\",\n",
    "           's': _marker_sizes,\n",
    "           \"label\": \"population\",\n",
    "           \"alpha\": 0.4,\n",
    "           \"cmap\": _cmap,\n",
    "           \"ax\": _ax}\n",
    "\n",
    "_ = (training_df.assign(residuals=pd.Series(_residuals, name=\"residuals\"))\n",
    "                .plot\n",
    "                .scatter(x=\"median_income\", y=\"residuals\", **_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Your System on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = joblib.load(\"../data/housing/testing.pkl\")\n",
    "\n",
    "testing_features_arr = preprocessing_pipeline.transform(testing_df)\n",
    "testing_target_arr = (testing_df.loc[:, \"median_house_value\"]\n",
    "                                .values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_predictions = (random_forest_grid_search.best_estimator_\n",
    "                                         .predict(testing_features_arr))\n",
    "\n",
    "_mse = metrics.mean_squared_error(testing_target_arr, _predictions)\n",
    "_mse**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_predictions = (gradient_boosting_randomized_search.best_estimator_\n",
    "                                                   .predict(testing_features_arr))\n",
    "\n",
    "_mse = metrics.mean_squared_error(testing_target_arr, _predictions)\n",
    "_mse**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lauch, Monitor, and Maintain Your System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
